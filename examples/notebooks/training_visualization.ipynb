{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackholio Agent Training Visualization\n",
    "\n",
    "This notebook provides comprehensive visualization and analysis of training runs for Blackholio agents.\n",
    "\n",
    "## Features\n",
    "- Load and visualize training logs\n",
    "- Compare multiple training runs\n",
    "- Analyze reward progression and learning curves\n",
    "- Identify training issues and optimization opportunities\n",
    "- Generate training reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import glob\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Training visualization notebook loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Training Data\n",
    "\n",
    "Load training logs from TensorBoard or custom logging files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataLoader:\n",
    "    def __init__(self, log_dir: str):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        \n",
    "    def load_tensorboard_data(self, experiment_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data from TensorBoard logs\"\"\"\n",
    "        try:\n",
    "            from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "            \n",
    "            event_file = self.log_dir / experiment_name\n",
    "            event_acc = EventAccumulator(str(event_file))\n",
    "            event_acc.Reload()\n",
    "            \n",
    "            # Extract scalar data\n",
    "            data = {}\n",
    "            for tag in event_acc.Tags()['scalars']:\n",
    "                scalar_events = event_acc.Scalars(tag)\n",
    "                steps = [e.step for e in scalar_events]\n",
    "                values = [e.value for e in scalar_events]\n",
    "                data[tag] = pd.Series(values, index=steps)\n",
    "                \n",
    "            return pd.DataFrame(data)\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"TensorBoard not available. Please install with: pip install tensorboard\")\n",
    "            return None\n",
    "    \n",
    "    def load_csv_data(self, experiment_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data from CSV logs\"\"\"\n",
    "        csv_file = self.log_dir / f\"{experiment_name}.csv\"\n",
    "        if csv_file.exists():\n",
    "            return pd.read_csv(csv_file)\n",
    "        else:\n",
    "            print(f\"CSV file not found: {csv_file}\")\n",
    "            return None\n",
    "\n",
    "# Initialize data loader\n",
    "log_dir = \"logs\"  # Change this to your logs directory\n",
    "loader = TrainingDataLoader(log_dir)\n",
    "\n",
    "# List available experiments\n",
    "if Path(log_dir).exists():\n",
    "    experiments = [p.name for p in Path(log_dir).iterdir() if p.is_dir()]\n",
    "    print(f\"Available experiments: {experiments}\")\n",
    "else:\n",
    "    print(f\"Log directory not found: {log_dir}\")\n",
    "    print(\"Please update the log_dir variable to point to your training logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific experiment data\n",
    "experiment_name = \"blackholio_agent_20250525\"  # Change this to your experiment name\n",
    "\n",
    "# Try loading from different sources\n",
    "training_data = None\n",
    "\n",
    "# Option 1: TensorBoard data\n",
    "training_data = loader.load_tensorboard_data(experiment_name)\n",
    "\n",
    "# Option 2: CSV data (if TensorBoard not available)\n",
    "if training_data is None:\n",
    "    training_data = loader.load_csv_data(experiment_name)\n",
    "\n",
    "# Option 3: Generate sample data for demonstration\n",
    "if training_data is None:\n",
    "    print(\"No training data found. Generating sample data for demonstration.\")\n",
    "    \n",
    "    # Generate realistic sample training data\n",
    "    np.random.seed(42)\n",
    "    n_steps = 1000\n",
    "    steps = np.arange(n_steps)\n",
    "    \n",
    "    # Simulate learning curves\n",
    "    episode_reward = np.cumsum(np.random.normal(0.1, 1.0, n_steps)) + 100 * np.log(steps + 1)\n",
    "    policy_loss = 2.0 * np.exp(-steps / 200) + 0.1 + np.random.normal(0, 0.05, n_steps)\n",
    "    value_loss = 1.5 * np.exp(-steps / 150) + 0.05 + np.random.normal(0, 0.03, n_steps)\n",
    "    entropy = 1.0 * np.exp(-steps / 300) + 0.01 + np.random.normal(0, 0.02, n_steps)\n",
    "    episode_length = 500 + 200 * np.log(steps + 1) + np.random.normal(0, 50, n_steps)\n",
    "    \n",
    "    training_data = pd.DataFrame({\n",
    "        'episode_reward': episode_reward,\n",
    "        'policy_loss': policy_loss,\n",
    "        'value_loss': value_loss,\n",
    "        'entropy': entropy,\n",
    "        'episode_length': episode_length,\n",
    "        'learning_rate': 3e-4 * np.exp(-steps / 500),\n",
    "        'fps': 20 + np.random.normal(0, 2, n_steps)\n",
    "    }, index=steps)\n",
    "\n",
    "print(f\"Training data shape: {training_data.shape}\")\n",
    "print(f\"Available metrics: {list(training_data.columns)}\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Progress Visualization\n",
    "\n",
    "Visualize key training metrics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(data: pd.DataFrame, metrics: List[str], window_size: int = 50):\n",
    "    \"\"\"Plot training metrics with smoothing\"\"\"\n",
    "    n_metrics = len(metrics)\n",
    "    fig, axes = plt.subplots(n_metrics, 1, figsize=(14, 4*n_metrics))\n",
    "    \n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        if metric in data.columns:\n",
    "            # Raw data\n",
    "            axes[i].plot(data.index, data[metric], alpha=0.3, color='lightblue', label='Raw')\n",
    "            \n",
    "            # Smoothed data\n",
    "            smoothed = data[metric].rolling(window=window_size, center=True).mean()\n",
    "            axes[i].plot(data.index, smoothed, linewidth=2, label=f'Smoothed (window={window_size})')\n",
    "            \n",
    "            axes[i].set_title(f'{metric.replace(\"_\", \" \").title()} Over Training')\n",
    "            axes[i].set_xlabel('Training Steps')\n",
    "            axes[i].set_ylabel(metric.replace('_', ' ').title())\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'Metric \"{metric}\" not found', \n",
    "                        transform=axes[i].transAxes, ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot key training metrics\n",
    "key_metrics = ['episode_reward', 'policy_loss', 'value_loss', 'entropy']\n",
    "plot_training_metrics(training_data, key_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Training Report\n",
    "\n",
    "Create a comprehensive training report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_report(data: pd.DataFrame, experiment_name: str = \"Training\"):\n",
    "    \"\"\"Generate a comprehensive training report\"\"\"\n",
    "    print(f\"Training Report: {experiment_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"\\nBasic Statistics:\")\n",
    "    print(f\"  Total training steps: {len(data)}\")\n",
    "    print(f\"  Data points collected: {data.count().sum()}\")\n",
    "    print(f\"  Missing data points: {data.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    if 'episode_reward' in data.columns:\n",
    "        rewards = data['episode_reward'].dropna()\n",
    "        print(f\"\\nReward Performance:\")\n",
    "        print(f\"  Mean reward: {rewards.mean():.2f}\")\n",
    "        print(f\"  Std reward: {rewards.std():.2f}\")\n",
    "        print(f\"  Max reward: {rewards.max():.2f}\")\n",
    "        print(f\"  Min reward: {rewards.min():.2f}\")\n",
    "        \n",
    "        # Learning progress\n",
    "        early_rewards = rewards.head(100).mean()\n",
    "        late_rewards = rewards.tail(100).mean()\n",
    "        improvement = (late_rewards - early_rewards) / abs(early_rewards) * 100\n",
    "        print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Training stability\n",
    "    if 'policy_loss' in data.columns and 'value_loss' in data.columns:\n",
    "        policy_loss = data['policy_loss'].dropna()\n",
    "        value_loss = data['value_loss'].dropna()\n",
    "        \n",
    "        print(f\"\\nTraining Stability:\")\n",
    "        print(f\"  Policy loss CV: {policy_loss.std() / policy_loss.mean():.3f}\")\n",
    "        print(f\"  Value loss CV: {value_loss.std() / value_loss.mean():.3f}\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    if 'fps' in data.columns:\n",
    "        fps = data['fps'].dropna()\n",
    "        print(f\"\\nPerformance:\")\n",
    "        print(f\"  Average FPS: {fps.mean():.1f}\")\n",
    "        print(f\"  FPS stability: {fps.std():.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "generate_training_report(training_data, experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
